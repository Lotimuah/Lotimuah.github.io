---
layout: article
title: DQN 논문 정리
tags: Paper_Review
#comments: true
#article_header:
#  type: cover
#  image:
#    src:
aside:
  toc: true
key: page-aside
---

  \* 이 포스트는 DeepMind의 [Playing Atari with Deep Reinforcement Learning](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf) 논문에 대한 내용을 정리한 글입니다.

  ----------------------------------------------------------------------

**분류** : Model-Free/Deep Q-Learning/DQN  


## Abstract

  - high-dimensional sensory input이 주어졌을 때, agent를 효과적으로 학습시키는 deep learning 알고리즘을 제안  
  - CNN model을 사용해 raw pixel을 input으로 받으면 future reward를 추정하는 value function을 output  
  - Atari 2600의 6종 아케이드 게임에서 기존 연구를 능가했으며, 그 중 3종의 게임에 대해서 human expert를 능가  


## Introduction

  이 논문이 발표되기 전까지 vision이나 speech같은 high-dimensional sensory data로부터 agent를 학습시키는 것은 RL의 오랜 과제였습니다. 그러나 Deep Learning이 발전하고 고차원의 feature들을 얻는 것이 가능해지면서 이를 RL에도 적용하려는 연구가 진행되었습니다.
